glance(fit)
report(fit)
lambda <- fulldata %>%
features(total_number_of_reviews, features = guerrero) %>%
pull(lambda_guerrero)
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 24)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(revenue, lambda) ~ trend() + season()),
ets = ETS(box_cox(revenue, lambda)),
arima = ARIMA(box_cox(revenue, lambda)),
nnetar = NNETAR(box_cox(revenue, lambda))
)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 6, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
96/12
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 12)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
ets_fit <- train %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
gg_tsresiduals(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
ets_fit <- train %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
ets_fit <- train %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(Employed, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(Employed, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
limit()
memory.limit()
R_MAX_MEM_SIZE
memory.size()
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
ets_fit <- train %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
gg_tsresiduals(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
gg_tsresiduals(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
View(ashbase)
decomp <- fulldata %>%
model(STL(total_number_of_reviews, robust = TRUE)) %>%
components(total_number_of_reviews)
decomp %>% autoplot
decomp %>% autoplot(trend + season_year)
fulldata$total_number_of_reviews <- (decomp$trend + decomp$season_year)
#Linear model
fit <- fulldata %>%
model(
TSLM(total_number_of_reviews~trend()+season())
)
#Fitting several models
lambda <- fulldata %>%
features(total_number_of_reviews, features = guerrero) %>%
pull(lambda_guerrero)
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 12)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
gg_tsresiduals(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit <- train %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
ets_fit %>%
forecast(h = 12) %>%
accuracy(holdout) %>%
select(.model, RMSE, MAPE)
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
### PREDICTIONS ###
lambda <- guerrero(fulldata$total_number_of_reviews, .period = 12)
lambda # 0.608 very close to being a sqrt
lambda <- as.integer(lambda)
### PREDICTIONS ###
lambda <- guerrero(fulldata$total_number_of_reviews, .period = 12)
lambda # 0.608 very close to being a sqrt
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
library(fpp3)
library(regclass)
library(dplyr)
library(ggplot2)
### DATA LOADING AND MANIPULATION ###
ashbase <- read.csv("asheville-airbnb-reviews.csv")
denbase <- read.csv("denver-airbnb-reviews.csv")
## Ash Data manipulation
ashbase$date <- make_yearmonth(year = ashbase$year, month = ashbase$month)
ash <- NA
ash <- ashbase %>% group_by(date) %>% summarise(count = n())
colnames(ash) <- c("date","asheville_number_of_reviews")
## Denver Data Manipulation
denbase$date <- make_yearmonth(year = denbase$year, month = denbase$month)
den <- NA
den <- denbase %>% group_by(date) %>% summarise(count = n())
colnames(den) <- c("date","denver_number_of_reviews")
## Joining data
fulldata <- full_join(ash,den, by = "date")
fulldata$total_number_of_reviews <- fulldata$asheville_number_of_reviews + fulldata$denver_number_of_reviews
## Ended up dropping these to make it easier predicting. Possibly remove from Code.
fulldata$asheville_number_of_reviews <- NULL
fulldata$denver_number_of_reviews <- NULL
fulldata <- fulldata %>%
as_tsibble()
### PREDICTIONS ###
#Splitting data
holdout_size <- 12
train <- head(fulldata, -holdout_size)
holdout <- tail(fulldata, holdout_size)
# # Validating split
# max(train$date)
# min(holdout$date)
#
# nrow(train)
# nrow(holdout)
### Smoothing for covid outliers
decomp <- fulldata %>%
model(STL(total_number_of_reviews, robust = TRUE)) %>%
components(total_number_of_reviews)
# decomp %>% autoplot
#
# decomp %>% autoplot(trend + season_year)
fulldata$total_number_of_reviews <- (decomp$trend + decomp$season_year)
## SELECTING BEST MODEL
#Fitting several models
lambda <- fulldata %>%
features(total_number_of_reviews, features = guerrero) %>%
pull(lambda_guerrero)
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 12)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
report(ets_fit)
gg_tsresiduals(ets_fit)
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
ets_fit %>%
forecast(h = 12)
# Storing Predictions to CSV
predictions <- ets_fit %>%
forecast(h = 12)
predictions.mean
predictions
predictions$.mean
### Storing Predictions to CSV
CSV$Date <- c("Jan 2021", "Feb 2021", "March 2021", "April 2021", "May 2021",
"June 2021", "July 2021", "August 2021", "September 2021",
"October 2021", "November 2021", "December 2021")
### Storing Predictions to CSV
CSV <- NULL
CSV$Date <- c("Jan 2021", "Feb 2021", "March 2021", "April 2021", "May 2021",
"June 2021", "July 2021", "August 2021", "September 2021",
"October 2021", "November 2021", "December 2021")
View(CSV)
CSV$Predictions <- predictions$.mean
View(CSV)
head(CSV)
### Storing Predictions to CSV
CSV <- df()
### Storing Predictions to CSV
CSV <- data.frame()
CSV$Date <- c("Jan 2021", "Feb 2021", "March 2021", "April 2021", "May 2021",
"June 2021", "July 2021", "August 2021", "September 2021",
"October 2021", "November 2021", "December 2021")
predictions <- ets_fit %>%
forecast(h = 12)
CSV$Predictions <- predictions$.mean
head(CSV)
### Storing Predictions to CSV
CSV <- data.frame(1:12)
CSV$Date <- c("Jan 2021", "Feb 2021", "March 2021", "April 2021", "May 2021",
"June 2021", "July 2021", "August 2021", "September 2021",
"October 2021", "November 2021", "December 2021")
predictions <- ets_fit %>%
forecast(h = 12)
CSV$Predictions <- predictions$.mean
head(CSV)
CSV$X1.12 <- NULL
head(CSV)
write.csv(CSV,file='Fianl Group Predictions.csv',row.names=FALSE)
write.csv(CSV,file='Final Group Predictions.csv',row.names=FALSE)
read.csv("Final Group Predictions.csv")
library(fpp3)
library(regclass)
library(dplyr)
library(ggplot2)
### DATA LOADING AND MANIPULATION ###
ashbase <- read.csv("asheville-airbnb-reviews.csv")
denbase <- read.csv("denver-airbnb-reviews.csv")
## Ash Data manipulation
ashbase$date <- make_yearmonth(year = ashbase$year, month = ashbase$month)
ash <- NA
ash <- ashbase %>% group_by(date) %>% summarise(count = n())
colnames(ash) <- c("date","asheville_number_of_reviews")
## Denver Data Manipulation
denbase$date <- make_yearmonth(year = denbase$year, month = denbase$month)
den <- NA
den <- denbase %>% group_by(date) %>% summarise(count = n())
colnames(den) <- c("date","denver_number_of_reviews")
## Joining data
fulldata <- full_join(ash,den, by = "date")
fulldata$total_number_of_reviews <- fulldata$asheville_number_of_reviews + fulldata$denver_number_of_reviews
## Ended up dropping these to make it easier predicting. Possibly remove from Code.
fulldata$asheville_number_of_reviews <- NULL
fulldata$denver_number_of_reviews <- NULL
fulldata <- fulldata %>%
as_tsibble()
### PREDICTIONS ###
#Splitting data
holdout_size <- 12
train <- head(fulldata, -holdout_size)
holdout <- tail(fulldata, holdout_size)
# # Validating split
# max(train$date)
# min(holdout$date)
#
# nrow(train)
# nrow(holdout)
### Smoothing for covid outliers
decomp <- fulldata %>%
model(STL(total_number_of_reviews, robust = TRUE)) %>%
components(total_number_of_reviews)
# decomp %>% autoplot
#
# decomp %>% autoplot(trend + season_year)
fulldata$total_number_of_reviews <- (decomp$trend + decomp$season_year)
## SELECTING BEST MODEL
#Fitting several models
lambda <- fulldata %>%
features(total_number_of_reviews, features = guerrero) %>%
pull(lambda_guerrero)
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 12)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
#Fitting best model
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
# #Checking out residuals/white noise
# report(ets_fit)
#
# gg_tsresiduals(ets_fit)
# Plot with full data
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
library(fpp3)
library(regclass)
library(dplyr)
library(ggplot2)
ashbase <- read.csv("asheville-airbnb-reviews.csv")
denbase <- read.csv("denver-airbnb-reviews.csv")
View(ashbase)
View(denbase)
## Ash Data manipulation
ashbase$date <- make_yearmonth(year = ashbase$year, month = ashbase$month)
ash <- NA
ash <- ashbase %>% group_by(date) %>% summarise(count = n())
colnames(ash) <- c("date","asheville_number_of_reviews")
## Denver Data Manipulation
denbase$date <- make_yearmonth(year = denbase$year, month = denbase$month)
den <- NA
den <- denbase %>% group_by(date) %>% summarise(count = n())
colnames(den) <- c("date","denver_number_of_reviews")
fulldata <- full_join(ash,den, by = "date")
fulldata$total_number_of_reviews <- fulldata$asheville_number_of_reviews + fulldata$denver_number_of_reviews
## Ended up dropping these to make it easier predicting. Possibly remove from Code.
fulldata$asheville_number_of_reviews <- NULL
fulldata$denver_number_of_reviews <- NULL
View(fulldata)
fulldata <- fulldata %>%
as_tsibble()
holdout_size <- 12
train <- head(fulldata, -holdout_size)
holdout <- tail(fulldata, holdout_size)
autoplot(fulldata)
decomp <- fulldata %>%
model(STL(total_number_of_reviews, robust = TRUE)) %>%
components(total_number_of_reviews)
decomp %>% autoplot
#
decomp %>% autoplot(trend + season_year)
fulldata$total_number_of_reviews <- (decomp$trend + decomp$season_year)
#Fitting several models
lambda <- fulldata %>%
features(total_number_of_reviews, features = guerrero) %>%
pull(lambda_guerrero)
train_cv <- train %>%
stretch_tsibble(.init = 48 , .step = 12)
fits <- train_cv %>%
model(
TSLM_ts = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + season()),
tslm_tf = TSLM(box_cox(total_number_of_reviews, lambda) ~ trend() + fourier(K = 6)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
ets = ETS(box_cox(total_number_of_reviews, lambda)),
arima = ARIMA(box_cox(total_number_of_reviews, lambda)),
nnetar = NNETAR(box_cox(total_number_of_reviews, lambda))
)
fits %>%
forecast(h = 12, times = 0) %>%
accuracy(train) %>%
arrange(RMSE)
#Fitting best model
ets_fit <- fulldata %>%
model(
ets = ETS(box_cox(total_number_of_reviews, lambda))
)
# Plot with full data
ets_fit %>%
forecast(h = 12) %>%
autoplot(fulldata)
(100*1200)
(100*1200) / 509600000
5^5
?choose
choose(10,4)
0.8 + 0.7 - (0.7*0.7)
0.8 + 0.7 - (0.8*0.7)
0.8^5
5^5
120/5
5^3
5^2
choose(10,4)
0.8 + 0.7 - (0.8*0.7)
(0.8*0.7)
0.8+0.7
1.5-0.56
